{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System\n",
    "import os\n",
    "#nltk.download('stopwords')\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "\n",
    "# Time\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "# Numerical\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Tools\n",
    "import itertools\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud,STOPWORDS\n",
    "\n",
    "# NLP\n",
    "import nltk\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import word_tokenize \n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy.sparse import hstack\n",
    "# from pywsd.utils import lemmatize_sentence\n",
    "\n",
    "# Preprocessing\n",
    "from sklearn import preprocessing\n",
    "from sklearn.utils import class_weight as cw\n",
    "from sklearn import svm\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer, ENGLISH_STOP_WORDS, TfidfTransformer\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from bs4 import BeautifulSoup\n",
    "from sklearn.utils.testing import ignore_warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "import re\n",
    "\n",
    "# Model Selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV,cross_val_predict\n",
    "\n",
    "# Machine Learning Models\n",
    "from sklearn.linear_model import LogisticRegression, LogisticRegressionCV, SGDClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, RandomForestClassifier, BaggingClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline, Pipeline\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn import metrics \n",
    "from sklearn.metrics import f1_score, accuracy_score,confusion_matrix,classification_report, roc_auc_score\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings(\"ignore\", category=ConvergenceWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/twitter_sentiment_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr=df\n",
    "#Beautiful Soup is a library that makes it easy to scrape information from web pages.\n",
    "#It sits atop an HTML or XML parser, providing Pythonic idioms for iterating, searching, and modifying the parse tree.\n",
    "df_pr[\"message\"] = df_pr[\"message\"].apply(lambda x: BeautifulSoup(x, \"lxml\").get_text())\n",
    "#print(df_pr[\"message\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pr[\"message\"] = df_pr[\"message\"].apply(lambda x: x.lower())\n",
    "#print(df_pr[\"message\"]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mrunm\\anaconda\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "# remove URLs, RTs, and twitter handles\n",
    "for i in range(len(df_pr['message'])):\n",
    "    df_pr['message'][i] = \" \".join([word for word in df_pr['message'][i].split()\n",
    "                                if 'http' not in word and '@' not in word and '<' not in word and word != 'rt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regex\n",
    "#Returning the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl\n",
    "#replace whatever except alphabets to space\n",
    "df_pr[\"message\"] = df_pr[\"message\"].apply(lambda x: re.sub(\"https?://[^a-zA-Z]\", \" \", x))\n",
    "# removing some punctuations\n",
    "df_pr[\"message\"] = df_pr[\"message\"].apply(lambda x: re.sub('[!@#$:).;,?&]', '', x))\n",
    "#replace tab with space\n",
    "df_pr[\"message\"] = df_pr[\"message\"].apply(lambda x: re.sub(\"\\s+\", \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>climate change is an interesting hustle as it ...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>watch beforetheflood right here as travels the...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>fabulous leonardo dicaprio's film on climate c...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>just watched this amazing documentary by leona...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>pranita biswasi a lutheran from odisha gives t...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  target\n",
       "0  climate change is an interesting hustle as it ...      -1\n",
       "1  watch beforetheflood right here as travels the...       1\n",
       "2  fabulous leonardo dicaprio's film on climate c...       1\n",
       "3  just watched this amazing documentary by leona...       1\n",
       "4  pranita biswasi a lutheran from odisha gives t...       2"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a pre-processed dataframe and renaming columns to ease the analysis\n",
    "clean_df=df_pr.rename(columns={\"message\": \"text\", \"sentiment\": \"target\"})\n",
    "clean_df=clean_df[[\"text\",\"target\"]]\n",
    "clean_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Logistic Regression with tfidf vectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 64.20 percent\n"
     ]
    }
   ],
   "source": [
    "# Define the vector of labels and matrix of features\n",
    "y = clean_df[\"target\"]\n",
    "X = clean_df[\"text\"]\n",
    "\n",
    "# Perform the train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=50)\n",
    "vct_tweet=TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "\n",
    "# Create sparse matrix from the tfidf vectorizer\n",
    "tfidf_train_x = vct_tweet.fit_transform(X_train)\n",
    "tfidf_test_x = vct_tweet.fit_transform(X_test)\n",
    "\n",
    "# Build a logistic regression model and print out the accuracy\n",
    "log_reg = LogisticRegression()\n",
    "log_reg.fit(tfidf_train_x,y_train)\n",
    "#ypred=log_reg.predict(tfidf_test_x)\n",
    "#print (tfidf_test_x.shape)\n",
    "scores = cross_val_score(log_reg,tfidf_test_x, y_test)\n",
    "acc = scores.mean()\n",
    "print (\"Accuracy: %0.2f percent\" % (acc *100))\n",
    "#print(\"Summary\"+classification_report(y_test, ypred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD CLassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.702241438161338"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a pipeline and running SGDCLassifer\n",
    "pipeline_sgd = Pipeline([\n",
    "    ('vect', CountVectorizer()),\n",
    "    ('tfidf',  TfidfTransformer()),\n",
    "    ('nb', SGDClassifier()),\n",
    "])\n",
    "model = pipeline_sgd.fit(X_train, y_train)\n",
    "y_predict = model.predict(X_test)\n",
    "f1_score(y_test,y_predict,average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparing and tuning Logistic Regression with penalties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1    0.523440\n",
      " 2    0.210673\n",
      " 0    0.175286\n",
      "-1    0.090601\n",
      "Name: target, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "#set up X and y\n",
    "X_train = clean_df['text']\n",
    "y_train = clean_df['target']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "#set up baseline \n",
    "print (y_train.value_counts(normalize=True))\n",
    "baseline = 0.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression(random_state=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf Vectorizer Score: 68.65 percent\n"
     ]
    }
   ],
   "source": [
    "# initalise the vectorizer \n",
    "vector_twt = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS)\n",
    "# fit the training data on the model\n",
    "vector_twt.fit(X_train)\n",
    "\n",
    "#transform training data into sparse matrix\n",
    "X_train_twt = vector_twt.transform(X_train)\n",
    "\n",
    "# cross val score/ predict for the four categories\n",
    "twt_score = cross_val_score(lr, X_train_twt, y_train, cv=4)\n",
    "tf_sc=twt_score.mean()\n",
    "print (\"Tfidf Vectorizer Score: %0.2f percent\" % (tf_sc *100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tfidf Vectorizer Score: 71.06 percent\n"
     ]
    }
   ],
   "source": [
    "# initalise the count vectorizer \n",
    "cvector_twt = CountVectorizer(stop_words=stopwords.words('english'))\n",
    "# fit the training data on the model\n",
    "cvector_twt.fit(X_train)\n",
    "\n",
    "#transform training data into sparse matrix\n",
    "X_train_cvt = cvector_twt.transform(X_train)\n",
    "\n",
    "# cross val score/ predict\n",
    "cvct_score = cross_val_score(lr, X_train_cvt, y_train, cv=4)\n",
    "cv_sc=cvct_score.mean()\n",
    "print (\"Tfidf Vectorizer Score: %0.2f percent\" % (cv_sc *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.71678471 0.7154194  0.71876067]\n"
     ]
    }
   ],
   "source": [
    "# Transform features \n",
    "cvect = CountVectorizer(ngram_range=(1,4)) \n",
    "cvect.fit(X_train)\n",
    "X_train_cvect= cvect.transform(X_train)\n",
    "X_test_cvect= cvect.transform(X_test)\n",
    "# fit with l1 \n",
    "model_l1 = LogisticRegressionCV(Cs=np.logspace(-10,10,21),penalty = 'l1',solver='liblinear',cv=3) \n",
    "model_l1.fit(X_train_cvect, y_train)\n",
    "\n",
    "print(\"Cross Validation Score:\", cross_val_score(model_l1,X_train_cvect,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with L1 Penalty: 71.67 percent\n"
     ]
    }
   ],
   "source": [
    "acc_l1=(cross_val_score(model_l1,X_train_cvect,y_train)).mean()\n",
    "print(\"Accuracy with L1 Penalty: %0.2f percent\" % (acc_l1 *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.73248571 0.7281338  0.73173438]\n"
     ]
    }
   ],
   "source": [
    "# fit with l2\n",
    "model_l2 = LogisticRegressionCV(Cs=np.logspace(-10,10,21),penalty = 'l2',solver='liblinear',cv=3) \n",
    "model_l2.fit(X_train_cvect, y_train)\n",
    "\n",
    "print(\"Cross Validation Score:\", cross_val_score(model_l2,X_train_cvect,y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with L1 Penalty: 73.08 percent\n"
     ]
    }
   ],
   "source": [
    "acc_l2=(cross_val_score(model_l2,X_train_cvect,y_train)).mean()\n",
    "print(\"Accuracy with L1 Penalty: %0.2f percent\" % (acc_l2 *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross Validation Score: [0.62008465 0.58178591 0.57445211]\n",
      "Accuracy For the Random Forest: 59.21 percent\n"
     ]
    }
   ],
   "source": [
    "# Random Forest Classifier\n",
    "y = clean_df[\"target\"]\n",
    "X = clean_df[\"text\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=50)\n",
    "\n",
    "# define stop words\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "#remove stopwords\n",
    "vectorizer = CountVectorizer(stop_words=stopwords)\n",
    "\n",
    "X = vectorizer.fit_transform(X)\n",
    "# running a random forest on the dataset by removing stopwords using the countverctorizer\n",
    "model3 = RandomForestClassifier(n_estimators=200, n_jobs=-1, class_weight='balanced', random_state=50)\n",
    "\n",
    "#Evaluate a score by cross-validation\n",
    "print(\"Cross Validation Score:\",cross_val_score(model, X, y, cv=3))\n",
    "accu_RF=(cross_val_score(model, X, y, cv=3)).mean()\n",
    "print(\"Accuracy For the Random Forest: %0.2f percent\" % (accu_RF *100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
